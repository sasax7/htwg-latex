1.Introduction

Das ist bereits eine sehr starke Gliederung f√ºr dein Grundlagen-Kapitel. Sie f√ºhrt den Leser logisch vom Anwendungsfall (Smart Building) √ºber die Daten (Zeitreihen) zum Problem (Anomalien) und den L√∂sungsans√§tzen (Methoden-Kategorien).

Aufbauend darauf k√∂nntest du noch zwei weitere Themenbl√∂cke in die "Fundamentals" aufnehmen, die dir sp√§ter in der Arbeit (insbesondere bei der Evaluation und Implementierung) sehr helfen werden.

Hier ist der erweiterte Vorschlag:

üí° Vorschlag 1: Vertiefung der f√ºr dich relevanten Methode
Dein jetziger Punkt "Was sind die Kategorien..." ist eine gute √úbersicht. Da du dich aber stark f√ºr probabilistische Prognosen interessierst, k√∂nntest du diesen Punkt ausbauen, um deine sp√§tere Methodenauswahl in Kapitel 4/5 vorzubereiten.

Erweiterter Punkt 2.4: Kategorien von Erkennungsmethoden

2.4.1 Distanz- und Dichtebasierte Methoden

(Kurz erkl√§ren, z.B. Isolation Forest, LOF, Matrix Profile )



2.4.2 Vorhersagebasierte Methoden (Prediction-based) ‚Äì Vertiefung

Hier legst du die Grundlage f√ºr deine sp√§tere L√∂sung.


Grundprinzip: Erkl√§re die Logik: Ein Modell lernt das "normale" Verhalten und sagt den n√§chsten Schritt voraus. Die Abweichung von der Realit√§t ist der Anomalie-Score.



Unterscheide (wichtig f√ºr dich!):

Punkt-Prognose (Point Forecasting): Das Modell sagt einen Wert voraus (z.B. "21.5¬∞C"). Der Score ist der Fehler (z.B. |actual - predicted|).

Probabilistische Prognose (Probabilistic Forecasting): Das Modell sagt eine Wahrscheinlichkeitsverteilung oder ein Konfidenzintervall voraus (z.B. "Der Wert liegt mit 95% Wahrscheinlichkeit zwischen 21.0¬∞C und 22.0¬∞C").

Deine Definition von Anomalie: Hier definierst du fundamental, dass eine Anomalie vorliegt, wenn der reale Messwert das vorhergesagte Intervall verl√§sst. Das ist eine viel robustere Definition als bei der Punkt-Prognose und leitet perfekt zu deiner Methodik in Kapitel 5 √ºber.

üìà Vorschlag 2: Grundlagen der Evaluierung
Du hast ein Kapitel 7 "Evaluation und Ergebnisse". Damit der Leser in Kapitel 7 versteht, was du da misst, musst du die Messgr√∂√üen (Metrics) in den Grundlagen definieren. Das ist ein sehr wichtiger, oft vergessener Punkt.

Neuer Punkt 2.5: Grundlagen der Evaluierung von Anomalieerkennung


Die Herausforderung: Erkl√§re kurz, warum die Evaluierung von Zeitreihen-Anomalien schwierig ist (z.B. "Wann ist eine Anomalie 'gefunden'? Wenn ein einziger Punkt markiert ist? Was ist mit einer leichten Zeitverz√∂gerung?").




Standard-Metriken (Punktbasiert):

Definiere kurz die Konfusionsmatrix (True Positive (TP), False Positive (FP), False Negative (FN), True Negative (TN)).

Definiere Precision, Recall und F1-Score.

Zeitreihen-spezifische Metriken (Sequenzbasiert):

Erkl√§re (wie in deiner PDF erw√§hnt), warum punktbasierte Metriken oft versagen (z.B. "Misalignment" oder "Lag"-Problem).



Stelle das Konzept von Range-based oder Event-based Metriken vor (z.B. Range-AUC oder VUS (Volume Under the Surface) ), die toleranter gegen√ºber leichten Verschiebungen sind und ganze anomale Ereignisse bewerten.

ü§ñ (Optional) Vorschlag 3: Grundlagen der Modell-Architekturen
Wenn dein "State of the Art" (Kapitel 3) und deine "Implementierung" (Kapitel 6) sehr tief in Deep Learning einsteigen, k√∂nntest du hier die Basis-Architekturen erkl√§ren.

Neuer Punkt 2.6: Relevante Modell-Architekturen (Basiswissen)


Was ist ein Rekurrentes Neuronales Netz (LSTM/GRU)? (Kurz: Modelle mit "Ged√§chtnis", gut f√ºr Sequenzen).


Was ist ein Autoencoder? (Kurz: Ein Modell zum Komprimieren und Rekonstruieren von Daten. Der Rekonstruktionsfehler wird als Anomalie-Score genutzt).


Was ist ein Transformer? (Kurz: Das Modell-Backbone von LLMs, das Zusammenh√§nge √ºber "Self-Attention" lernt).

Was ist ein Foundation Model? (Kurz: Ein sehr gro√ües Modell, das auf riesigen, diversen Daten vortrainiert wurde und dann per "Zero-Shot" oder "Finetuning" auf spezifische Probleme (wie deine Energiedaten) angewendet wird).


2. Grundlagen (Background)

    2.1 Anwendungsbereich: Smart Buildings und Energiemanagement

    2.2 Datenbasis: Zeitreihen (Univariat vs. Multivariat)

    2.3 Problemstellung: Arten von Anomalien (Punkt, Kontext, Kollektiv)

    2.4 Kategorien der Erkennungsmethoden

    2.4.1 √úberblick: Distanz-, Dichte- und Vorhersagebasierte Ans√§tze

    2.4.2 Vertiefung: Logik der Vorhersagebasierten Anomalieerkennung (Punkt- vs. Probabilistische Prognose)

    2.5 Evaluierungsmethodik: Metriken zur Erfolgsmessung

    2.5.1 Punktbasierte Metriken (Precision, Recall, F1-Score)

    2.5.2 Sequenzbasierte Metriken (z.B. VUS/Range-based)

    (Optional, falls viel DL genutzt wird)

    2.6 Grundlagen moderner Architekturen (z.B. Transformer, Foundation Models)


3.State of the Art (oder: Related Work)
    Welche konkreten Algorithmen und Paper (z.B. LSTM-AD, Matrix Profile, Isolation Forest) gibt es zu diesen Kategorien?
    
4.Proposed Approach (oder: Conceptual Approach / My Considerations for a Solution)

5.Conception and Methodology (oder: Design and Methodology)

6.Implementation

7.Evaluation and Results

8.Conclusion and Future Outlook (oder: Conclusion and Future Work)