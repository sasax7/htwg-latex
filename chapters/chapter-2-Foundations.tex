\chapter{Foundations}
\label{chap:fundamentals}
This chapter establishes the theoretical and methodological foundations required for a comprehensive understanding of the subsequent research. The analysis begins with an examination of the technical characteristics and physical composition of building energy data to define the operational parameters. Subsequently, the fundamental concepts of anomalies are explored, encompassing the classification of specific types and their manifestation in temporal data. This positioning allows for the integration of the current use case into the broader field of \ac{TSAD}. Finally, Chapter~\ref{chap:state-of-the-art} traces the technical evolution of detection methodologies and provides a systematic review of the current \ac{SOTA}.
\section{Characteristics of Building Energy Data}
\label{sec:building-energy-data}

Building-energy telemetry constitutes a multivariate, multimodal, and non-stationary stochastic process governed by physical, behavioural, and technical drivers. Effective anomaly detection therefore requires formal consideration of the structural and statistical properties of these data.

\subsection{Multivariate Structure}
\label{subsec:building-energy-multivariate-ts}

Building energy data is inherently multivariate and interdependent. In addition to aggregate meter readings, relevant variables include environmental conditions, occupancy, and subsystem states. Cross-variable dependencies are fundamental: changes in environmental drivers induce correlated changes in technical system loads. Consequently, anomaly detection must operate on multivariate joint behaviour rather than on isolated univariate series.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{images/multivariate-timeseries.png}
	\caption{Representative multivariate time series showing the main meter load together with occupancy (people count) and outdoor temperature. The plot illustrates how multiple interdependent variables evolve jointly over time.}
	\label{fig:multivariate-timeseries}
\end{figure}

\subsection{Causal Chain of Energy Consumption}
\label{subsec:causal-chain-energy-consumption}

Energy consumption emerges from a causal chain spanning demand generation, control logic, and mechanical execution. Environmental and occupancy conditions generate service demand; controllers translate demand into actuation commands; mechanical subsystems execute these commands, producing measurable energy use. Deviations observed at aggregate meters therefore frequently originate from faults located in upstream sensing or control layers.


\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{images/Energy-Causal-Chain.jpg}
	\caption{Causal chain of building energy consumption from demand over control to supply layer.}
	\label{fig:energy-causal-chain}
\end{figure}

Understanding the causal chain, as illustrated in Figure~\ref{fig:energy-causal-chain}, is a prerequisite for localizing anomalous behavior within building systems. A deviation observed in the building’s main meter often originates from a fault located in a preceding stage of the technical hierarchy, such as a sensor error or a logic failure in the control layer.

For instance, a malfunctioning temperature sensor reporting an erroneous heat spike triggers a cascade of responses. The control layer interprets this false data as a thermal requirement and initiates a cooling command to counteract the perceived heat. This signal causes the supply layer to activate mechanical components, such as cooling pumps and compressors. These devices consume electrical energy to satisfy the requested cooling load. Consequently, the aggregate output layer, represented by the building's main energy meter, records a significant increase in consumption. In this scenario, the measured energy spike is not a result of an actual physical need but acts as a symptom of a failure located deeper in the technical hierarchy.

\subsubsection{HVAC and Environmental Drivers}

HVAC systems dominate building energy demand. Thermal gradients, solar radiation, humidity, and scheduling logic determine cooling and heating loads. Suboptimal control strategies, scheduling conflicts, and mechanical degradation induce baseline drift and excessive consumption, generating anomalies that are often operationally normal yet energetically inefficient.


\subsubsection{Occupancy and Internal Loads}
\label{subsec:internal-loads-occupancy}

Human activity introduces stochastic variability through lighting, appliance use, and thermal gains. Behavioural interventions can decouple consumption from environmental drivers, while IT infrastructure introduces discrete operational regimes. These effects contribute to multimodality and regime-dependent energy patterns.

\subsubsection{Structural Moderators and Data Integrity}
\label{subsec:structural-technical-influences}

Building envelope characteristics and thermal inertia modulate system response dynamics. Interdependencies between subsystems propagate anomalies across services. Digital measurement infrastructure introduces non-physical artifacts, including missing values and aggregation spikes, which must be distinguished from physical faults during preprocessing.


\subsection{Temporal Dependence and Persistence}
\label{subsec:temporal-autocorrelation-persistence}

Building-energy telemetry exhibits strong temporal autocorrelation caused by thermal inertia, operational ramp-up dynamics, and persistent high-load device states. Consequently, short-term system behaviour is highly predictable under nominal operation, while slow-developing faults and sustained inefficiencies may remain concealed within otherwise smooth trajectories.

This persistence simultaneously stabilizes short-term forecasting and undermines detection of long-duration anomalies, particularly when sequential models rapidly absorb anomalous regimes into their predictive baseline.

\subsection{Seasonality and Periodicity}
\label{subsec:periodic-variations-seasonality}

Building-energy consumption follows pronounced daily, weekly, and seasonal periodicities driven by occupancy cycles, control schedules, and climatic seasons. These regime-dependent patterns form a repetitive operational fingerprint.

Anomaly detection must therefore distinguish contextual violations of expected periodic regimes (e.g., weekday-level consumption during weekends) from absolute deviations.
\subsection{Statistical Distribution and Non-Stationarity}
\label{subsec:statistical-distribution-stochastic-noise}

Empirical building-energy distributions deviate substantially from unimodal Gaussian assumptions and exhibit multimodal mixture structures with heavy tails due to discrete operational regimes and heterogeneous subsystem interactions. Deterministic point estimates are therefore insufficient to represent normative behaviour.

Sparse coverage of extreme weather and rare operational states introduces causal ambiguity and increases false anomaly rates for previously unobserved but physically valid conditions. Furthermore, building-energy telemetry is non-stationary; long-term baseline drift caused by seasonal transitions, equipment degradation, and persistent occupancy changes continuously shifts normative distributions, necessitating probabilistic, context-aware modeling.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.9\textwidth]{images/mixture-destribution.png}
	\caption{Empirical distribution of the building's main meter (15-minute kWh values, histogram) with an overlaid single normal distribution and a Gaussian mixture model with five components, illustrating the mismatch between a unimodal Gaussian model and the multimodal, heavy-tailed structure of real building energy data.}
	\label{fig:mixture-distribution}
\end{figure}

Figure~\ref{fig:mixture-distribution} illustrates this effect on real data: the measured main-meter consumption concentrates in several dense regions at lower loads and exhibits a pronounced right tail. A single normal distribution smooths over these structures and underestimates tail probabilities, whereas the fitted Gaussian mixture adapts to the multiple modes and better traces the empirical density.


\subsection{Data Acquisition and Semantic Structure}
\label{subsec:data-acquisition-telemetry}

The transformation of physical energy consumption into digital telemetry follows a multi-stage acquisition pipeline that converts electrical quantities into structured multivariate time series suitable for algorithmic analysis.

\begin{description}
	\item[Ontological Modeling:] To ensure interpretability and causal localization, the telemetry is mapped to a semantic ontology that encodes the physical and logical relationships between meters, subsystems, and devices~\cite{ElionaOntologies}. This ontological layer enables detected anomalies to be localized within the technical hierarchy rather than remaining aggregated deviations at the main meter level.
	\item[Standardized Units:] Raw meter readings are converted into standardized physical units (e.g., kWh) to ensure consistency across heterogeneous hardware and communication interfaces.
\end{description}

\subsection{Data Continuity and Transmission Artifacts}
\label{subsec:communication-artifacts}

The integrity of telemetry streams depends on the stability of the communication infrastructure. Network-level distortions introduce non-physical artifacts that must be distinguished from actual building faults.

\begin{description}
	\item[Transmission Gaps:] Communication failures produce missing values that interrupt temporal continuity and require correction during preprocessing.
	\item[Aggregation Spikes:] Buffered data retransmission following outages may produce virtual load spikes, reflecting delayed reporting rather than physical surges in energy demand.
\end{description}

\subsection{Synthesis of Data Characteristics}
\label{subsec:synthesis-energy-data-complexity}

Building-energy telemetry constitutes a multivariate, multimodal, and non-stationary stochastic process governed by a causal chain spanning demand, control, and mechanical execution. Anomalies observed at aggregate meters therefore represent manifestations of upstream technical and behavioural faults.

These data exhibit strong temporal autocorrelation and persistence, regime-dependent seasonality, multimodal mixture distributions, and digital transmission artifacts introduced by the acquisition pipeline. Consequently, effective anomaly detection must satisfy the following formal requirements:

\begin{enumerate}
	\item \textbf{Probabilistic multivariate modelling}\label{req:probabilistic-mixture}\\
	Expected energy behaviour must be modelled probabilistically as a multivariate mixture distribution rather than as a deterministic point estimate, so that multimodal regimes and cross-variable dependencies are represented explicitly.

	\item \textbf{Robustness to temporal dependence and persistence}\label{req:robust-persistence}\\
	Detection must remain robust under strong autocorrelation, long-duration regime persistence, and seasonal pattern shifts, ensuring that sustained faults are not absorbed into the learned baseline.

	\item \textbf{Separation of physical faults and digital artifacts}\label{req:artifact-separation}\\
	Digital measurement artifacts\textemdash such as transmission gaps and aggregation spikes\textemdash must be distinguished from physical system anomalies through explicit preprocessing and data-quality handling.
\end{enumerate}

Taken together, these characteristics and requirements formally define the modelling assumptions and architectural constraints that guide the anomaly detection methodologies developed in this thesis.


\section{Foundations of Anomaly Detection}
\label{sec:fundamentals-anomaly-detection}

Anomaly detection aims to identify observations or patterns that deviate from an implicit notion of normality. In time-series anomaly detection (TSAD), deviations are defined relative to temporal structure, persistence, and regime-dependent behaviour rather than isolated numerical values. The taxonomy adopted in this work follows the benchmark framework proposed by Paparrizos et al.~\cite{paparrizos2022tsb}.

\subsection{Dimensionality and Normality Regimes}
\label{subsec:dimensionality-normality-modes}

The complexity of anomaly detection is governed by the dimensionality of the time series and the number of normative operational regimes.

\begin{description}
	\item[Dimensionality:] Univariate time series describe a single system variable, whereas multivariate time series jointly model multiple interdependent variables. The dataset analyzed in this work is multivariate, combining aggregate energy consumption with environmental and occupancy drivers to resolve causal ambiguity.

	\item[Normality Regimes:] Building-energy telemetry operates under multiple normative regimes driven by seasonal, operational, and occupancy-dependent contexts. Consequently, “normal” behaviour is regime-specific rather than globally invariant.
\end{description}

The analyzed data is therefore classified as multivariate with multi-mode normality, necessitating detection models that adapt to shifting baselines and cross-variable dependencies.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{images/Univariate-Multivariate-normalities.jpg}
	\caption{Schematic illustration of time series types along two axes---dimensionality (univariate vs.~multivariate) and normality regimes (single-mode vs.~multi-mode). Adapted from Boniol et al.'s tutorial on new trends in time series anomaly detection~\cite{Boniol2023NewTrends}.}
	\label{fig:univariate-multivariate-normalities}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{images/types-anomalies.jpg}
	\caption{Taxonomy of time series anomalies along structural and multiplicity dimensions, distinguishing global and contextual point anomalies, subsequence-based anomalies, and their occurrence as single, multiple different, or multiple similar events. Adapted from Boniol et al.'s tutorial on new trends in time series anomaly detection~\cite{Boniol2023NewTrends}.}
	\label{fig:anomaly-taxonomy}
\end{figure}

\subsection{Structural Classes of Anomalies}

\begin{description}
  \item[Point Anomalies:] Individual observations that deviate from expected behaviour.
  \item[Global Point Anomalies:] Deviations outside the global historical range.
  \item[Contextual Point Anomalies:] Deviations from regime-dependent normative behaviour defined by temporal or exogenous context.
  \item[Subsequence Anomalies:] Deviations manifested through abnormal temporal patterns.
\end{description}

\subsection{Multiplicity of Occurrence}

\begin{description}
  \item[Single Anomalies:] Isolated anomalous events.
  \item[Multiple Similar Anomalies:] Recurrent manifestations of the same anomaly pattern.
  \item[Multiple Different Anomalies:] Co-occurring anomalies of heterogeneous types.
\end{description}

\subsection{Research Scope}

This work focuses on contextual point anomalies in multivariate building-energy telemetry. High-frequency subsequence anomalies manifest as contextual point deviations in aggregated energy series and are therefore addressed implicitly.

A central methodological challenge is the detection of multiple similar anomalies under non-stationarity, as recurrent inefficiencies may be absorbed into learned baselines. The proposed framework explicitly addresses this normality-drift problem through probabilistic modeling and controlled baseline adaptation.

\section{Methodological Approaches to Anomaly Detection}
\label{sec:methodological-approaches}

Anomaly detection transforms raw time-series telemetry into actionable information by assigning each observation a degree of abnormality and mapping it to a binary decision boundary.

\subsection{Anomaly Scores}

Most detection algorithms output an anomaly score $s_i$ per timestamp, which quantifies deviation from learned normative behaviour. Binary alerts are obtained by thresholding this score, yielding a time series of nominal and anomalous states.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{images/anomaly_score.png}
	\caption{Example of an anomaly score $s_i \in [0,1]$ aligned with the underlying time series. A threshold of 0.8 separates normal points from those flagged as anomalous.}
	\label{fig:anomaly-score}
\end{figure}

\subsection{Learning Paradigms}

The applicability of detection methods is governed by the availability of labelled data:
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{images/superviced-unsuperviced.jpg}
	\caption{Schematic overview of supervised, semi-supervised, and unsupervised learning paradigms for anomaly detection, adapted from Boniol et al.'s tutorial on new trends in time series anomaly detection~\cite{Boniol2023NewTrends}.}
	\label{fig:learning-paradigms}
\end{figure}

\begin{description}
	\item[Supervised:] Requires explicit labels for both normal and anomalous states; rarely feasible in building operations.
	\item[Semi-Supervised:] Learns normative behaviour from assumed healthy historical data; commonly used in building-energy monitoring.
	\item[Unsupervised:] Operates without labelled baselines; typically applied during system commissioning or cold-start phases.
\end{description}



\subsection{Families of Detection Methods}

Anomaly detection approaches are grouped into three methodological families:

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{images/distance-dencity-forecast.jpg}
	\caption{Hierarchical taxonomy of anomaly detection methods grouped into distance-based, density-based, and prediction-based families, adapted from Boniol et al.'s tutorial on new trends in time series anomaly detection~\cite{Boniol2023NewTrends}.}
	\label{fig:method-taxonomy}
\end{figure}

\begin{description}
	\item[Distance-Based:] Identify anomalous subsequences by pattern dissimilarity.
	\item[Density-Based:] Detect low-probability observations in learned feature distributions.
	\item[Prediction-Based:] Identify deviations via residuals between predicted and observed values, including forecasting- and reconstruction-based variants.
\end{description}

This thesis focuses on prediction-based approaches, as they are the only methodological family that provides an explicit expected-value baseline, enabling deviations to be quantified in physical units and directly translated into financial impact. This property is essential for contextual building-energy anomaly detection and economic loss estimation.

\section{Benchmarking Foundations}
\label{sec:benchmarking-foundations}

To determine how well an anomaly detection system works, it must be evaluated against a dataset where the correct outcomes are already known. This process is referred to as benchmarking and relies on comparing the model's decisions with a reference set of labels, the \gls{ground-truth}, to quantify detection performance.

\subsection{Binary Labeling and Ground Truth}
\label{subsec:binary-labeling-ground-truth}

The foundation of any benchmark is a labeled dataset in which each observation is assigned a binary label indicating whether it is considered normal or anomalous. In this context, a label of $0$ denotes normal operation and a label of $1$ denotes an anomaly, such as a fault or unusual event. When an algorithm analyzes this dataset, it produces its own sequence of binary decisions. Benchmarking assesses how closely these model-generated labels align with the original \gls{ground-truth} labels.

\subsection{The Confusion Matrix: Four Possible Outcomes}
\label{subsec:confusion-matrix}

When the model's predictions are compared to the \gls{ground-truth}, each observation falls into one of four categories. These outcomes are summarized in a \gls{confusion-matrix}, which serves as a scorecard for the detection system:

\begin{description}
	\item[True Positive (\ac{TP}):] The model correctly identifies an anomaly; the ground truth label is $1$ and the model predicts $1$.

	\item[True Negative (\ac{TN}):] The model correctly identifies normal operation; the ground truth label is $0$ and the model predicts $0$.

	\item[False Positive (\ac{FP}):] The model raises a false alarm; it predicts an anomaly ($1$) while the ground truth label is normal ($0$).

	\item[False Negative (\ac{FN}):] The model misses an anomaly; the ground truth label is $1$ but the model predicts normal operation ($0$).
\end{description}

These four counts form the quantitative basis for most evaluation metrics used in anomaly detection benchmarks.

\subsection{Measuring Success: Precision, Recall, and the F1 Score}
\label{subsec:precision-recall-f1}

The entries of the \gls{confusion-matrix} are used to derive summary metrics that characterize different aspects of a model's performance. Three central measures in anomaly detection are \gls{precision}, \gls{recall}, and the \ac{F1} score.

\gls{precision} quantifies how reliable the alarms are. It answers the question: when the model flags an anomaly, how often is this decision correct? Formally, precision is defined as the ratio of correctly detected anomalies to all observations that the model classified as anomalous,
\begin{equation}
	\mathrm{Precision} = \frac{TP}{TP + FP}.
\end{equation}
A high precision value indicates that the model rarely raises false alarms.

\gls{recall} quantifies how many anomalies are successfully detected. It answers the question: of all anomalies that actually occurred, how many did the model identify? Recall is defined as
\begin{equation}
	\mathrm{Recall} = \frac{TP}{TP + FN}.
\end{equation}
A high recall value indicates that the model is sensitive to anomalous behavior and misses few faults.

In practice, there is often a trade-off between \gls{precision} and \gls{recall}. A model that labels almost every point as anomalous may achieve high recall but very low precision, whereas an overly conservative model may exhibit the opposite behavior. The \ac{F1} score provides a single scalar summary by combining precision and recall through their harmonic mean,
\begin{equation}
	F1 = 2 \cdot \frac{\mathrm{Precision} \cdot \mathrm{Recall}}{\mathrm{Precision} + \mathrm{Recall}}.
\end{equation}

A high \ac{F1} score indicates that the model achieves a balanced compromise: it detects a large fraction of true anomalies while keeping the number of false alarms at a manageable level. In many benchmarking studies, this score is used as the primary indicator for ranking competing detection methods.

\section{Synthesis of Foundations}
\label{subsec:synthesis-foundations}
The examination of building energy data in Section~\ref{sec:building-energy-data} and the formal taxonomies of anomaly detection in Section~\ref{sec:fundamentals-anomaly-detection} reveal a highly specialized operational environment. Because building energy consumption is an aggregate signal driven by a complex causal chain (see Subsection~\ref{subsec:causal-chain-energy-consumption}), it is fundamentally characterized as a multivariate time series (see Subsection~\ref{subsec:building-energy-multivariate-ts}). This multidimensionality necessitates a focus on contextual point anomalies (see Subsection~\ref{subsec:taxonomy-anomalies}), as abnormality is defined primarily relative to the prevailing environmental and operational state rather than to a single global range. Furthermore, the temporal aggregation of energy data into 15-minute or hourly intervals (see Subsection~\ref{subsec:statistical-distribution-stochastic-noise}) effectively transforms high-frequency rhythmic faults into detectable point-based deviations in the aggregated series.

The implementation of detection strategies is constrained by several domain-specific factors. Human-driven consumption and manual behavioral interventions introduce a stochastic element to the time series (see Subsection~\ref{subsec:internal-loads-occupancy}), where these probabilistic variations deviate from standard Gaussian models and require detection frameworks capable of distinguishing between random noise and technical faults (see Subsection~\ref{subsec:statistical-distribution-stochastic-noise}). Simultaneously, the physical degradation of mechanical components causes a gradual increase in the power required for the same service output (see Subsection~\ref{subsec:structural-technical-influences}), ensuring that the definition of normality is non-stationary and undergoes baseline drift over long temporal scales.

Within this context, semi-supervised and unsupervised learning paradigms (see Subsection~\ref{subsec:learning-paradigms}) introduce a fundamental technical contradiction when historical data is utilized in the absence of expert-annotated fault histories. If persistent or repetitive anomalies were already present during the training period, the model incorrectly incorporates these deviations into its learned definition of normality. This risk of normality drift, particularly in the presence of multiple similar anomalies (see Subsection~\ref{subsec:taxonomy-anomalies}), leads to suppressed alerts and remains a central constraint for the subsequent methodological selection.

The establishment of these data-driven requirements and theoretical classifications lays the foundation for a systematic evaluation of the current state of the art in Chapter~\ref{chap:state-of-the-art}, where concrete algorithmic choices are assessed against the constraints of building energy data.
