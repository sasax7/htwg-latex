\chapter{Introduction}
\label{chap:introduction}

\section{Motivation and Economic Context}

Buildings account for approximately 30\% of global final energy consumption and more than 50\% of global electricity consumption~\cite{alvsauskas2024world}. Empirical studies indicate that avoidable operational anomalies\textemdash encompassing technical faults, suboptimal control strategies, and persistent behavioural misuse\textemdash account for between 4\% and 18\% of building energy use~\cite{roth2004energy}. These inefficiencies frequently remain undetected because conventional threshold-based monitoring systems are not triggered.

Non-technical losses represent a quantifiable economic burden. Electricity theft results in annual losses exceeding 6~billion~USD in the United States alone~\cite{mcdaniel2009security}. Furthermore, reports from the World Bank indicate that in some developing countries up to 50\% of distributed electricity is lost due to theft ~\cite{antmann2009reducing}. Such patterns of energy misuse constitute an economically relevant class of anomalies. While modern \ac{BAS} are capable of detecting deviations from nominal operation, they typically neither quantify the associated financial impact nor provide systematic root-cause attribution, thereby limiting their operational and economic usefulness.

\section{Digitalization of Buildings and Data Explosion}

The implementation of \ac{AMI}, which combines smart meters with communication networks, is expanding globally. In the United States, smart meters had been deployed for approximately 77\% of households and businesses by 2022, with the installed base projected to grow to about 134~million devices in 2024 and 142~million in 2026~\cite{enlit2024smartmeters}. The increasing integration of digital infrastructure and sub-metering in modern building environments generates vast repositories of high-frequency telemetry. This abundance of data provides a unique opportunity for the application of advanced artificial-intelligence techniques that thrive on large-scale, high-resolution multivariate data to identify previously undetectable deviations.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{images/Global-Smart-Electricity-Meter-Adoption-2024-by-Region-vweb.png}
	\caption{Global smart electricity meter adoption by region in 2024, illustrating the varying levels of AMI penetration across markets~\cite{iotanalytics2024smartmeters}.}
	\label{fig:global-smart-meter-adoption}
\end{figure}

\section{Why Current Building Automation Systems Fail}

Most deployed Building Automation Systems (BAS) rely on static rule-based logic and univariate statistical thresholds applied to individual sensor streams. Such approaches are structurally incapable of capturing the multivariate, context-dependent nature of building-energy behaviour and are therefore unable to distinguish between legitimate operational regime changes and true anomalous states.

More recent data-driven and machine-learning-based detection methods exhibit fundamental limitations. Many approaches operate on deterministic point predictions that fail to represent the stochastic, multimodal, and non-stationary characteristics of building-energy time series. As a result, these models impose context-agnostic deviation boundaries that treat identical absolute residuals as equally anomalous across fundamentally different operational regimes, leading to structurally incorrect anomaly semantics.

Sequential forecasting-based detectors further suffer from two critical failure modes when applied to sustained anomalies: (i) error propagation, where anomalous values corrupt the sliding input window and destabilize future predictions, and (ii) rapid baseline adaptation, where models quickly absorb anomalous states as normal operation, causing long-duration anomalies to disappear from the anomaly score signal :contentReference[oaicite:1]{index=1}. These effects undermine both detection reliability and financial loss quantification.

Furthermore, the majority of published anomaly-detection benchmarks rely on inadequately annotated datasets, implicit anomaly assumptions, and global point-anomaly definitions that can be captured by trivial threshold rules but fail to represent contextual and multivariate operational anomalies. These limitations significantly reduce the transferability of reported performance to real-world building operation.

Finally, existing systems rarely provide automated root-cause attribution or translate detected deviations into quantifiable financial impact, thereby limiting their practical value for operational decision-making and maintenance prioritization.

\section{Emergence of Foundation Models for Time Series}

The emergence of \ac{TSFM}, such as Chronos-2~\cite{ansari2025chronos}, marks a new paradigm in building-energy analytics. These models are designed to process multivariate, non-stationary, and stochastic data and provide probabilistic output distributions instead of single-value predictions. This enables the construction of normative operational bands that capture multimodal building behaviour and allow contextual deviations to be distinguished from normal variability.

A key advantage of foundation models is their zero-shot generalization capability. In contrast to asset-specific forecasting models, TSFMs do not require per-meter training or frequent retraining. Multivariate building telemetry can be provided directly as contextual input, while optional fine-tuning can be performed jointly across entire building portfolios. This makes foundation models particularly well suited to the inherently non-stationary nature of building-energy data and enables scalable deployment across large building estates.

\section{System Context and Industrial Relevance}

This research is conducted in the context of the Eliona IoT Building Management Platform (see Section~\ref{sec:eliona-system-context}), a production-grade multi-tenant system deployed in commercial and industrial building portfolios worldwide. Eliona integrates heterogeneous building automation systems, smart meters, and environmental sensors into a unified telemetry and analytics layer.

The anomaly-detection framework developed in this thesis is not a laboratory prototype, but a fully integrated subsystem within Elionaâ€™s operational architecture. It processes live building telemetry, performs stochastic anomaly detection, quantifies financial impact, localizes probable root causes, and exposes actionable insights through a production-ready frontend used by facility managers and energy operators.

This real-world deployment context defines both the functional requirements and the architectural constraints of the proposed methodology, including scalability, robustness to missing data, non-stationary baselines, explainability, and economic interpretability.

\section{Problem Scope and Research Contributions}

This thesis addresses the problem of detecting, economically quantifying, and diagnostically localizing contextual anomalies in multivariate building-energy time series within large-scale, non-stationary operational environments.

In contrast to traditional threshold-based and deterministic forecasting approaches, this work formulates anomaly detection as a stochastic, multivariate, context-dependent modeling problem. The objective is the design and implementation of an integrated, production-ready anomaly intelligence system that not only detects deviations, but also explains their technical origin, quantifies their economic impact, and derives operationally meaningful recommendations.

The proposed framework models expected building-energy behaviour as a multivariate, multimodal mixture distribution, allowing deviations to be evaluated probabilistically rather than against static thresholds. This formulation explicitly accounts for non-stationary baselines caused by seasonal shifts, occupancy changes, and long-term system drift, preventing legitimate regime transitions from being misclassified as anomalies. Methodologically, the work focuses on detecting \ac{MCPA} and translating them into financially interpretable metrics.

The primary contributions of this thesis are:

\begin{itemize}
  \item A formalization of building-energy anomaly detection as multivariate contextual point anomaly detection under multimodality and non-stationarity.
  \item An empirical and theoretical critique of deterministic forecasting-based anomaly detectors and their structural failure modes.
  \item A stochastic detection framework based on probabilistic normative bands derived from foundation models.
  \item A financially interpretable quantification layer that transforms deviations into monetary loss estimates.
  \item A hierarchical root-cause attribution pipeline grounded in building ontologies and causal dependencies.
  	\item A domain-specific multivariate benchmark dataset generated via \ac{BOPTEST} with labeled contextual fault scenarios (see Section~\ref{sec:boptest-benchmark}).
  	\item A fully integrated, scalable, multi-tenant implementation deployed within a production IoT building platform.
  	\item A methodological foundation for the development of a universal energy foundation model supporting zero-shot anomaly detection and standardized baseline comparison in accordance with the \ac{IPMVP}.
\end{itemize}

This work assumes that the historical baseline used for model context represents nominal building operation. The framework is therefore designed to detect deviations emerging after baseline establishment and does not aim to retroactively identify faults that were already persistently present in historical reference data. Furthermore, the scope is limited to aggregated building-energy telemetry and does not target high-frequency electrical fault detection, equipment-level vibration analysis, or cybersecurity intrusion detection.
